{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the essential imports in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we read the training and testing data for our complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:\\\\Classes\\\\train.tsv', sep='\\t')\n",
    "test = pd.read_csv('D:\\\\Classes\\\\test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we noticed a lot of our data is missing in the brand names column , we fill out the missing values with the string 'missing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['brand_name'] = train['brand_name'].fillna('missing').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 LAYER NEURAL NETWORK MODEL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train this model with tensorflow as the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "#from lr_schedule import _cosine_decay_restarts, _exponential_decay\n",
    "#from sklearn.metrics import rmse\n",
    "#from nn_module import embed, encode, attend\n",
    "#from nn_module import word_dropout\n",
    "#from nn_module import dense_block, resnet_block\n",
    "#from optimizer import LazyPowerSignOptimizer, LazyAddSignOptimizer, LazyAMSGradOptimizer, LazyNadamOptimizer\n",
    "#from utils import _makedirs\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XNN(object):\n",
    "    def __init__(self, params, target_scaler, logger):\n",
    "        self.params = params\n",
    "        self.target_scaler = target_scaler\n",
    "        self.logger = logger\n",
    "        _makedirs(self.params[\"model_dir\"], force=True)\n",
    "        self._init_graph()\n",
    "        self.gvars_state_list = []\n",
    "\n",
    "        # 14\n",
    "        self.bias = 0.01228477\n",
    "        self.weights = [\n",
    "            0.00599607, 0.02999416, 0.05985384, 0.20137787, 0.03178938, 0.04612812,\n",
    "            0.05384821, 0.10121514, 0.05915169, 0.05521121, 0.06448063, 0.0944233,\n",
    "            0.08306157, 0.11769992\n",
    "        ]\n",
    "        self.weights = np.array(self.weights).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Find root mean square logarithmic error for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_rmsle(h, y):\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_missing(dataset):\n",
    "    dataset.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_categories(train, test):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    le.fit(np.hstack([train.category_name, test.category_name]))\n",
    "    train.category_name = le.transform(train.category_name)\n",
    "    test.category_name = le.transform(test.category_name)\n",
    "\n",
    "    le.fit(np.hstack([train.brand_name, test.brand_name]))\n",
    "    train.brand_name = le.transform(train.brand_name)\n",
    "    test.brand_name = le.transform(test.brand_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing raw item descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_raw_inputs(train, test):\n",
    "    raw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n",
    "\n",
    "    tok_raw = Tokenizer()\n",
    "    tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "    train[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\n",
    "    test[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\n",
    "    train[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\n",
    "    test[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keras_data(dataset):\n",
    "    X = {'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ),\n",
    "         'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n",
    "         'brand_name': np.array(dataset.brand_name),\n",
    "         'category_name': np.array(dataset.category_name),\n",
    "         'item_condition': np.array(dataset.item_condition_id),\n",
    "         'num_vars': np.array(dataset[[\"shipping\"]])}\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another RMSLE(Root mean square Logarithmic error) calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model definition:--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_RNN_model():\n",
    "    # Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    category_name = Input(shape=[1], name=\"category_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "\n",
    "    # Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "\n",
    "    # RNN layers\n",
    "    rnn_layer1 = GRU(16)(emb_item_desc)\n",
    "    rnn_layer2 = GRU(8)(emb_name)\n",
    "\n",
    "    # Main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten()(emb_brand_name),\n",
    "        Flatten()(emb_category_name),\n",
    "        Flatten()(emb_item_condition),\n",
    "        rnn_layer1,\n",
    "        rnn_layer2,\n",
    "        num_vars])\n",
    "\n",
    "    main_l = Dropout(0.1)(Dense(128)(main_l))\n",
    "    main_l = Dropout(0.1)(Dense(64)(main_l))\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(1, activation=\"linear\")(main_l)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model([name, item_desc, brand_name, category_name, item_condition, num_vars], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = preprocess_missing(train)\n",
    "test = preprocess_missing(test)\n",
    "\n",
    "preprocess_categories(train, test)\n",
    "preprocess_raw_inputs(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing sequences in the training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "max_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))),\n",
    "                       np.max(test.seq_name.apply(lambda x: len(x)))])\n",
    "\n",
    "max_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x))),\n",
    "                                   np.max(test.seq_item_description.apply(lambda x: len(x)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Selecting maximal values based on the original work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NAME_SEQ = 10\n",
    "MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_TEXT = np.max([np.max(train.seq_name.max()),\n",
    "                   np.max(test.seq_name.max()),\n",
    "                   np.max(train.seq_item_description.max()),\n",
    "                   np.max(test.seq_item_description.max())])+2\n",
    "MAX_CATEGORY = np.max([train.category_name.max(),\n",
    "                       test.category_name.max()])+1\n",
    "MAX_BRAND = np.max([train.brand_name.max(),\n",
    "                    test.brand_name.max()])+1\n",
    "MAX_CONDITION = np.max([train.item_condition_id.max(),\n",
    "                        test.item_condition_id.max()])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000019503E68630>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling values\n",
    "train[\"target\"] = np.log(train.price+1)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train[\"target\"] = target_scaler.fit_transform(train.target.values.reshape(-1, 1))\n",
    "pd.DataFrame(train.target).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training data for crossval\n",
    "dtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad data for Keras\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "X_test = get_keras_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_name (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_desc (InputLayer)          (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        52900       brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 10)        13110       category_name[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 75, 50)       12954400    item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 50)       12954400    name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 16)           3216        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 8)            1416        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          6528        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,994,321\n",
      "Trainable params: 25,994,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_RNN_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1467709 samples, validate on 14826 samples\n",
      "Epoch 1/5\n",
      "1467709/1467709 [==============================] - 209s 142us/step - loss: 0.0333 - mean_absolute_error: 0.1398 - rmsle_cust: 0.0162 - val_loss: 0.0200 - val_mean_absolute_error: 0.1077 - val_rmsle_cust: 0.0142\n",
      "Epoch 2/5\n",
      "1467709/1467709 [==============================] - 208s 142us/step - loss: 0.0201 - mean_absolute_error: 0.1076 - rmsle_cust: 0.0138 - val_loss: 0.0171 - val_mean_absolute_error: 0.0991 - val_rmsle_cust: 0.0131\n",
      "Epoch 3/5\n",
      "1467709/1467709 [==============================] - 207s 141us/step - loss: 0.0174 - mean_absolute_error: 0.0999 - rmsle_cust: 0.0130 - val_loss: 0.0159 - val_mean_absolute_error: 0.0958 - val_rmsle_cust: 0.0126\n",
      "Epoch 4/5\n",
      "1467709/1467709 [==============================] - 206s 141us/step - loss: 0.0159 - mean_absolute_error: 0.0956 - rmsle_cust: 0.0125 - val_loss: 0.0154 - val_mean_absolute_error: 0.0944 - val_rmsle_cust: 0.0124\n",
      "Epoch 5/5\n",
      "1467709/1467709 [==============================] - 206s 140us/step - loss: 0.0150 - mean_absolute_error: 0.0928 - rmsle_cust: 0.0122 - val_loss: 0.0154 - val_mean_absolute_error: 0.0945 - val_rmsle_cust: 0.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19503d17a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 30000\n",
    "epochs = 5\n",
    "model.fit(X_train, dtrain.target,\n",
    "          epochs=epochs,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          validation_data=(X_valid, dvalid.target),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validate model\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.49363815774040193\n"
     ]
    }
   ],
   "source": [
    "# Find the RMSLE\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:, 0]\n",
    "v_rmsle = find_rmsle(y_true, y_pred)\n",
    "print(\"RMSLE: \" + str(v_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test dataset validation\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Result to csv\n",
    "result = test[[\"test_id\"]]\n",
    "result[\"price\"] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.377471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.302700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.843052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16.273266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.120021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.668484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9.604812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>40.218586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>39.758251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10.539124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>46.147152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>14.921098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>35.159206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>43.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>33.136814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>10.124529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>17.752920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17.353943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>41.073196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>6.323465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>9.450256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>9.935121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>10.942597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>18.230034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>38.413731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>8.164574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>18.477032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>8.515210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>51.687607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>9.576496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693329</th>\n",
       "      <td>693329</td>\n",
       "      <td>23.209789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693330</th>\n",
       "      <td>693330</td>\n",
       "      <td>22.336962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693331</th>\n",
       "      <td>693331</td>\n",
       "      <td>15.640974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693332</th>\n",
       "      <td>693332</td>\n",
       "      <td>29.143955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693333</th>\n",
       "      <td>693333</td>\n",
       "      <td>18.797556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693334</th>\n",
       "      <td>693334</td>\n",
       "      <td>65.911766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693335</th>\n",
       "      <td>693335</td>\n",
       "      <td>7.510698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693336</th>\n",
       "      <td>693336</td>\n",
       "      <td>16.367952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693337</th>\n",
       "      <td>693337</td>\n",
       "      <td>18.443403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693338</th>\n",
       "      <td>693338</td>\n",
       "      <td>14.867719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693339</th>\n",
       "      <td>693339</td>\n",
       "      <td>13.577919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693340</th>\n",
       "      <td>693340</td>\n",
       "      <td>5.043384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693341</th>\n",
       "      <td>693341</td>\n",
       "      <td>323.087189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693342</th>\n",
       "      <td>693342</td>\n",
       "      <td>7.078773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693343</th>\n",
       "      <td>693343</td>\n",
       "      <td>17.133440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693344</th>\n",
       "      <td>693344</td>\n",
       "      <td>32.973942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693345</th>\n",
       "      <td>693345</td>\n",
       "      <td>13.853344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693346</th>\n",
       "      <td>693346</td>\n",
       "      <td>36.038460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693347</th>\n",
       "      <td>693347</td>\n",
       "      <td>43.203472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693348</th>\n",
       "      <td>693348</td>\n",
       "      <td>40.573055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693349</th>\n",
       "      <td>693349</td>\n",
       "      <td>7.806740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693350</th>\n",
       "      <td>693350</td>\n",
       "      <td>8.989470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693351</th>\n",
       "      <td>693351</td>\n",
       "      <td>12.393934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693352</th>\n",
       "      <td>693352</td>\n",
       "      <td>11.840585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693353</th>\n",
       "      <td>693353</td>\n",
       "      <td>10.502136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693354</th>\n",
       "      <td>693354</td>\n",
       "      <td>17.415342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693355</th>\n",
       "      <td>693355</td>\n",
       "      <td>28.533318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693356</th>\n",
       "      <td>693356</td>\n",
       "      <td>6.715685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693357</th>\n",
       "      <td>693357</td>\n",
       "      <td>13.960980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693358</th>\n",
       "      <td>693358</td>\n",
       "      <td>12.571104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        test_id       price\n",
       "0             0   11.377471\n",
       "1             1   11.302700\n",
       "2             2   34.843052\n",
       "3             3   16.273266\n",
       "4             4    7.120021\n",
       "5             5   10.668484\n",
       "6             6    9.604812\n",
       "7             7   40.218586\n",
       "8             8   39.758251\n",
       "9             9   10.539124\n",
       "10           10   46.147152\n",
       "11           11   14.921098\n",
       "12           12   35.159206\n",
       "13           13   43.663086\n",
       "14           14   33.136814\n",
       "15           15   10.124529\n",
       "16           16   17.752920\n",
       "17           17   17.353943\n",
       "18           18   41.073196\n",
       "19           19    6.323465\n",
       "20           20    9.450256\n",
       "21           21    9.935121\n",
       "22           22   10.942597\n",
       "23           23   18.230034\n",
       "24           24   38.413731\n",
       "25           25    8.164574\n",
       "26           26   18.477032\n",
       "27           27    8.515210\n",
       "28           28   51.687607\n",
       "29           29    9.576496\n",
       "...         ...         ...\n",
       "693329   693329   23.209789\n",
       "693330   693330   22.336962\n",
       "693331   693331   15.640974\n",
       "693332   693332   29.143955\n",
       "693333   693333   18.797556\n",
       "693334   693334   65.911766\n",
       "693335   693335    7.510698\n",
       "693336   693336   16.367952\n",
       "693337   693337   18.443403\n",
       "693338   693338   14.867719\n",
       "693339   693339   13.577919\n",
       "693340   693340    5.043384\n",
       "693341   693341  323.087189\n",
       "693342   693342    7.078773\n",
       "693343   693343   17.133440\n",
       "693344   693344   32.973942\n",
       "693345   693345   13.853344\n",
       "693346   693346   36.038460\n",
       "693347   693347   43.203472\n",
       "693348   693348   40.573055\n",
       "693349   693349    7.806740\n",
       "693350   693350    8.989470\n",
       "693351   693351   12.393934\n",
       "693352   693352   11.840585\n",
       "693353   693353   10.502136\n",
       "693354   693354   17.415342\n",
       "693355   693355   28.533318\n",
       "693356   693356    6.715685\n",
       "693357   693357   13.960980\n",
       "693358   693358   12.571104\n",
       "\n",
       "[693359 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Out of all the models we tried, this model has the least RMSLE error and predicts the prices closer to the original training dataset prices.\n",
    "####  0.49363815774040193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
